# ğŸµ MoodTunes
MoodTunes is a real-time music recommendation service designed to deliver personalized music based on your current activity or situation. Instead of relying on user history or preferences, MoodTunes uses speech inputs to understand the user's current emotional and situational context, providing music that fits the momentâ€”whether you're studying, exercising, traveling, or dealing with a breakup.  

## ğŸš€ Key Features
> - **Emotion Analysis**   
>   : User input is processed using a combination of STT and LLM to extract emotion and context tags.
> - **Context-Aware Recommendations**   
>   : Based on the extracted tags, a content-based filtering approach is used to match the userâ€™s current context with relevant songs from a curated database.
> - **Real-time Recommendations**    
>   : Recommendations are generated on-the-fly based on live input.

## ğŸ“Š Datasets Used

This project utilizes several external datasets to provide accurate music recommendations based on emotional and situational context. The following datasets were used:

- **[DEAM Dataset](https://github.com/drfeinberg/DEAM-Emotion-Music-Dataset)**
- **[EmoMusic Dataset](https://github.com/MTG/emoMusic)**
- **[Million Song Dataset](http://millionsongdataset.com/)**

## ğŸ› ï¸ Tech Stack
> - Frontend: React.js
> - Backend: FastAPI
> - Model: PyTorch


## ğŸ—ï¸ Project Structure
```
MoodTunes/
â”‚
â”œâ”€â”€ ...
â”‚
â”œâ”€â”€ README.md            
â””â”€â”€ requirements.txt  
```

## ğŸš§ Installation
```
pip install -r requirements.txt
```
## ğŸ“š Usage

## ğŸ§  How It Works

## ğŸ‘¥ Contributing

## ğŸ“œ License
This project is licensed under the MIT License - see the LICENSE file for details.
